***知识点***
1.mapreduce，storm，spark都是基于大数据的运算框架。
三者是同级位置，只是侧重点不同。
都可以运行在yarn资源调度框架上，他们等于说是统一接口的不同实现而已。
其实基于这个思想，我们也可以自己开发个类似于mapreduce的运算框架。

2.源码跟踪的目的是更加深入的了解代码背后的实现逻辑，同时不再害怕跟踪源码，毕竟做过就有底气了。

3.dat文件

4.序列化


5.封装思想：
把一些属性封装为一个类

6.一般涉及到数据在不同机子间的传输，涉及到序列化问题。
一般自定义的类要实现序列化机制，数据传到别的机子才可以识别。

jdk自带的序列化机制没有hadoop的序列化机制精简。
jdk自带的还传递了类的继承结构信息
而hadoop只传递数据，不关心结构。

7.非法数据
也称为脏数据，因为用户提交的数据总是千奇百怪，
你的程序要容错性强。
不能因为用户的某个不规范输出就挂掉了。
简单可以用try..catch捕获。
复杂点可以写逻辑处理，一般是if...else结构

***收获****
1.有些二进制文件，用vi打开是乱码的，但是用UltraEdit就没事，可见UE之强大！
2.在pycharm中连接github
1）在github界面建立一个repository
2）git clone到本地
3）用pycharm打开
4）配置git.exe（类似于配置jdk和python.exe等）
5）切换到自己的分支
6）添加或者更改内容。然后add，commit，push

3.身为程序猿，不要轻易说某个东西好或者不好。世界上万事万物都是相对的。
即使你说他是对或是不对，你得拿出让人信服的证据。
举例：一朵鲜花长在牛粪上，不一定是坏事，会让花越来越美。
要谦虚，要成熟（不要随波逐流，说别人闲话啥的），这样就和别人拉开距离了。不在一个Level，和他们境界不一样。



***问题****
1.在本地push：
Failed with error: The remote end hung up unexpectedly The remote end hung up unexpectedly RPC failed; curl 56 OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 10054
